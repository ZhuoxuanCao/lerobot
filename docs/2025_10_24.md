# 本周工作

## **so101的模仿学习：更新黑框-优化遥操作**

- 原版的放置点是使用的纯色黑框，现在在黑框的基础上加上红色的标记线

  ![image-20251024121600056](C:\Users\MECHREUO\AppData\Roaming\Typora\typora-user-images\image-20251024121600056.png)

- 在遥操作时，加入：**悬停-校正-放置”三段式操作**

### 测试及问题

**样本1：**

- 训练集：将右边绿色方块，放在左边的**黑色红色**框里20次，并且加入三段式操作
- 训练细节：
  - 减少epoch数，不再追求极致loss
  - 加入数据增强（亮度、模糊等，HF自带）

- 准确率：相比于之前有提升，目前准确率大约为50%（将方块大致放进框里），但有时依然放不进去
- 问题：
  - offset的问题依然存在
  - 模型过拟合向电机的问题依然存在

在该样本中，我们尝试**移除了黑红框**，它依然会将绿色方块放过去，但是相比之前更加犹豫

说明我们的优化方向是正确的（加强视觉信号特征+减缓机械臂移动速度），可以进一步往这个方向努力。



### 优化思路&算法底层的修改

- ~~能不能做一个推方块的policy？~~，遥操作困难，难以实现高精度的推箱子
- ~~拆分policy，先做一个抓取policy，然后再做一个放置policy~~，hold暂时不可行，未找到电机不断电的办法
- ~~为不同的遥操作数据引入评分系统，给高质量操作高分，低质量操作低分。~~遥操作-数据集的合成-训练，的代码已经耦合，加入这个功能需要解耦，工程量大，暂时先不考虑。
- 引入一些机制让模型注意力更多在视觉上，减小电机信号的权重，增加视觉信号的权重：
  - 在训练过程中，**随机**（概率 p=0.3）将机器人状态 `robot_state` 置零，即参考dropout的思路，训练时随机丢弃一些电机数据。希望只能依赖视觉来预测动作
  - 





## 下一步工作？



有办法惩罚吗？类似RL，或者减小电机信号的权重？增加视觉信号的权重？

移开黑框，不放下，测试

引入一些机制让模型注意力更多在视觉上

能不能做一个推方块的policy？

**在一个policy里尝试失误-纠正，没放好，然后夹起来**

拆分policy，hold是否可行，电机不断电，我们先验证只做定位







**11月7号，seminar**

- 定义一下我们的工作，我们提出了一套可以本地部署的、基于小模型的、agentic 架构的、机器人动作规划、任务分解、replan的系统

- 了解大领域的痛点，已有一些基于agentic的框架都是大模型，我们的贡献是提出本地小模型部署
- **感知模块**：解决空间感知问题，SLM会更加的严重，我们涉及了一个空间感知的agent，一个tree of small LM
  - 我们的数据集
  - 我们的tree框架
  - 展示我们的实验结果，是否有tree

- **planning**，痛点是物理规律理解，上下文不足
  - 引入了RAG，改动rag

- **机器人控制**：解决的问题是，不需要IK，我们使用IL，