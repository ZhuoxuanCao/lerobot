## 录制 (Recording)

### 录制指令

文件中包含以下用于数据录制的 `lerobot-record` 指令：

**清除缓存指令**

```
rm /home/cao/.cache/huggingface/lerobot/cao/so101_stack_blue_on_green_v1
```

**启用视频保存 (测试版)**

```bash
# 启用视频保存
# 测试版
lerobot-record \
  --robot.type=so101_follower \
  --robot.port=/dev/ttyACM1 \
  --robot.id=follower_arm_v1 \
  --robot.cameras="{ \
    top:  {type: opencv, index_or_path: /dev/video0, width: 320, height: 240, fps: 20, warmup_s: 5}, \
    hand: {type: opencv, index_or_path: /dev/video2, width: 640, height: 480, fps: 20, warmup_s: 5} \
  }" \
  --teleop.type=so101_leader \
  --teleop.port=/dev/ttyACM0 \
  --teleop.id=leader_arm_v1 \
  --display_data=false \
  --dataset.repo_id=${USER}/so101_stack_blue_on_green_v1 \
  --dataset.num_episodes=5 \
  --dataset.single_task="stack_blue_on_green" \
  --dataset.episode_time_s=60 \
  --dataset.reset_time_s=20 \
  --dataset.fps=20 \
  --dataset.push_to_hub=false \
  --dataset.video=true \
  --dataset.num_image_writer_processes=1 \
  --dataset.num_image_writer_threads_per_camera=2 \
  --play_sounds=true 
```

**启用视频保存 (v6 - 绿色方块在底层)**

```bash
# 启用视频保存
v1 v2是在有问题的机械臂上测试的，我们现在放弃，新机械臂从v3开始

# 将绿色方块放在底层

lerobot-record \
  --robot.type=so101_follower \
  --robot.port=/dev/ttyACM1 \
  --robot.id=follower_arm_v1 \
  --robot.cameras="{ \
    top:  {type: opencv, index_or_path: /dev/video0, width: 320, height: 240, fps: 30, warmup_s: 5}, \
    hand: {type: opencv, index_or_path: /dev/video2, width: 640, height: 480, fps: 30, warmup_s: 5} \
  }" \
  --teleop.type=so101_leader \
  --teleop.port=/dev/ttyACM0 \
  --teleop.id=leader_arm_v1 \
  --display_data=false \
  --dataset.repo_id=${USER}/so101_stack_green_on_bottom_v6 \
  --dataset.num_episodes=30 \
  --dataset.single_task="stack_green_on_bottom" \
  --dataset.episode_time_s=45 \
  --dataset.reset_time_s=12 \
  --dataset.fps=30 \
  --dataset.push_to_hub=false \
  --dataset.video=true \
  --dataset.num_image_writer_processes=1 \
  --dataset.num_image_writer_threads_per_camera=2 \
  --play_sounds=false
```

### 录制记录

#### **绿色方块放在底层 (so101\_stack\_green\_on\_bottom)**

  * v1，v2：使用老机械臂，各执行了10次，帧率为20

  * v3：使用新机械臂，执行了15次，帧率为30, --dataset.single\_task="stack\_green\_on\_bottom"

  * v4：使用新机械臂，执行了40次，帧率为30, --dataset.single\_task="stack\_green\_on\_bottom" （五层纸，黑布，黑框）

    

    **v1234都是demo，从v4开始，放置区的方块以gbr顺序排列**

    

  * v5：使用新机械臂，执行了40次，帧率为30, --dataset.single\_task="stack\_green\_on\_bottom" （五层纸，黑布，黑框，加上一个蓝色一个紫色在待抓取区域）

  * v6：使用新机械臂，执行了30次，帧率为30, --dataset.single\_task="stack\_green\_on\_bottom" （五层纸，黑布，黑框+红线，加上一个蓝色一个紫色在待抓取区域，加入等待）

#### **蓝色方块放在第二层 (so101\_stack\_blue\_on\_second\_layer)**

  * v1：执行了20次，帧率为30，10次绿色在下面，10次紫色在下面，--dataset.single\_task="stack\_blue\_on\_second\_layer"

  * v2：执行了10次，帧率为30，10次绿色在下面--dataset.single\_task="stack\_blue\_on\_second\_layer"(用于合并数据集训练的测试)

  * v3：执行了10次，帧率为30，10次紫色在下面--dataset.single\_task="stack\_blue\_on\_second\_layer"(用于合并数据集训练的测试)

    

    **v123都是demo，从v4开始，放置区的方块以gbr顺序排列**

    

  * v4：执行了15次，帧率为30，15次绿色在下面--dataset.single\_task="stack\_blue\_on\_second\_layer"(用于合并数据集训练的测试，空心黑框，下面绿色方块在中间)

  * v5：执行了20次，帧率为30，20次绿色在下面--dataset.single\_task="stack\_blue\_on\_second\_layer"(用于合并数据集训练的测试，空心黑框，下面绿色方块在黑框的上下左右）

  * v6：执行了20次，帧率为30，20次绿色在下面--dataset.single\_task="stack\_blue\_on\_second\_layer"(用于合并数据集训练的测试，空心黑框，下面绿色方块在黑框的四角）

-----

## 🧠 训练 (Training)

### 训练指令

文件中包含以下用于模型训练的 `lerobot-train` 指令：

**训练 "blue\_on\_second\_layer\_v4"**

```bash
  lerobot-train \
  --dataset.repo_id=cao/so101_stack_blue_on_second_layer_v4 \
  --policy.type=act \
  --output_dir=outputs/act/so101_stack_blue_on_second_layer_v4_act \
  --job_name=so101_stack_blue_on_second_layer_v4 \
  --policy.device=cuda \
  --batch_size=16 \
  --steps=10000 \
  --save_checkpoint=true \
  --save_freq=5000 \
  --log_freq=50 \
  --eval_freq=1000 \
  --wandb.enable=true \
  --wandb.project=lerobot-act \
  --wandb.notes="SO-101 stacking task: blue squares at second layer, using the v4 dataset" \
  --policy.push_to_hub=false
```

**训练 "green\_on\_bottom\_v6"**

```bash
   lerobot-train \
  --dataset.repo_id="cao/so101_stack_green_on_bottom_v6" \
  --policy.type=act \
  --output_dir=outputs/act/so101_so101_stack_green_on_bottom_v6_act \
  --job_name=so101_stack_green_on_bottom_v6 \
  --policy.device=cuda \
  --batch_size=16 \
  --steps=15000 \
  --save_checkpoint=true \
  --save_freq=5000 \
  --log_freq=50 \
  --eval_freq=1000 \
  --wandb.enable=true \
  --wandb.project=lerobot-act \
  --wandb.notes="SO-101 stacking task: green squares at bottom, using the v6 dataset" \
  --policy.push_to_hub=false
```

**训练 "blue\_mix\_v456" (多数据集)**

```bash
lerobot-train \
  --dataset.repo_id="cao/so101_stack_blue_on_second_layer_v4,cao/so101_stack_blue_on_second_layer_v5,cao/so101_stack_blue_on_second_layer_v6" \
  --policy.type=act \
  --output_dir=outputs/act/so101_blue_mix_v456 \
  --job_name=so101_blue_mix_v456_with_aug \
  --policy.device=cuda \
  --batch_size=16 \
  --steps=20000 \
  --save_checkpoint=true \
  --save_freq=5000 \
  --log_freq=50 \
  --eval_freq=1000 \
  --dataset.image_transforms.enable=true \
  --dataset.image_transforms.max_num_transforms=3 \
  --wandb.enable=true \
  --wandb.project=lerobot-act \
  --wandb.notes="SO-101 blue stacking v4+v5+v6 with image augmentation" \
  --policy.push_to_hub=false
```

**关于多数据集训练的修改说明**

> 为了尝试兼容多数据集训练，我们修改了`lerobot/datasets/factory.py` 文件内容，以及注释了lerobot/src/lerobot/configs/train.py的110-111行，如果有问题我们可以随时恢复源代码

**训练 "stack\_v6\_dropout\_p0.3" (Modality Dropout)**

```bash
lerobot-train \
  --dataset.repo_id="cao/so101_stack_green_on_bottom_v6" \
  --policy.type=act \
  --output_dir=outputs/act/so101_modality_dropout_p03 \
  --job_name=so101_stack_v6_dropout_p0.3 \
  --policy.device=cuda \
  --batch_size=16 \
  --steps=15000 \
  --save_checkpoint=true \
  --save_freq=5000 \
  --log_freq=50 \
  --eval_freq=1000 \
  --wandb.enable=true \
  --wandb.project=lerobot-act \
  --wandb.notes="SO-101 stacking: modality dropout p=0.3 to fix systematic placement bias" \
  --policy.push_to_hub=false \
  --policy.use_modality_dropout=true \
  --policy.modality_dropout_prob=0.3
```

### 训练记录

#### **绿色方块放在底层 (so101\_stack\_blue\_on\_second\_layer)，记录**

  * v3：使用so101\_stack\_green\_on\_bottom\_v3，输出outputs/act/so101\_stack\_green\_on\_bottom\_v3\_act，bs=16，steps=10000
  * v5：使用so101\_stack\_green\_on\_bottom\_v5，输出outputs/act/so101\_stack\_green\_on\_bottom\_v5\_act，bs=16，steps=20000
  * v6：使用so101\_stack\_green\_on\_bottom\_v6，输出outputs/act/so101\_stack\_green\_on\_bottom\_v6\_act，bs=16，steps=15000
  * **so101_stack_v6_dropout_p0.3**：使用 so101_stack_green_on_bottom_v6，输出 outputs/act/so101_modality_dropout_p03，bs=16，steps=15000 (备注：使用 modality dropout p=0.3)

#### **蓝色方块放在第二层 (so101\_stack\_blue\_on\_second\_layer)，记录**

  * v1：使用so101\_stack\_blue\_on\_second\_layer\_v1，输出outputs/act/so101\_stack\_blue\_on\_second\_layer\_v1\_act，bs=16，steps=12500
  * v2：使用so101\_stack\_blue\_on\_second\_layer\_v2 & so101\_stack\_blue\_on\_second\_layer\_v3，输出outputs/act/so101\_stack\_blue\_on\_second\_layer\_mix\_v1\_act，bs=16，steps=20000
  * v3：使用so101\_stack\_blue\_on\_second\_layer\_v4，输出outputs/act/so101\_stack\_blue\_on\_second\_layer\_v4\_act，bs=16，steps=10000
  * so101\_blue\_mix\_v456，使用so101\_stack\_blue\_on\_second\_layer\_v4 5 6进行训练，bs=16，steps=20000

-----

## 工作 (Work / 评估)

此部分包含使用 `lerobot-record` 结合已训练策略（`--policy.path`）进行评估的指令。

**评估 "so101\_stack\_blue\_on\_second\_layer\_v1\_act"**

```bash
lerobot-record \
  --robot.type=so101_follower \
  --robot.port=/dev/ttyACM1 \
  --robot.id=follower_arm_v1 \
  --robot.cameras="{ \
    top: {type: opencv, index_or_path: /dev/video0, width: 320, height: 240, fps: 30}, \
    hand: {type: opencv, index_or_path: /dev/video2, width: 640, height: 480, fps: 30} \
  }" \
  --display_data=false \
  --dataset.repo_id=${USER}/eval_so101_stack_blue_on_second_layer_v1 \
  --dataset.single_task="stack_blue_on_second_layer" \
  --dataset.num_episodes=5 \
  --dataset.episode_time_s=30 \
  --dataset.fps=30 \
  --dataset.push_to_hub=false \
  --dataset.video=true \
  --play_sounds=false \
  --policy.path=outputs/act/so101_stack_blue_on_second_layer_v1_act/checkpoints/last/pretrained_model
```

**评估 "so101\_stack\_blue\_on\_second\_layer\_v4\_act"**

```bash
  lerobot-record \
  --robot.type=so101_follower \
  --robot.port=/dev/ttyACM1 \
  --robot.id=follower_arm_v1 \
  --robot.cameras="{ top: {type: opencv, index_or_path: /dev/video0, width: 320, height: 240, fps: 30}, hand: {type: opencv, index_or_path: /dev/video2, width: 640, height: 480, fps: 30} }" \
  --teleop.type=so101_leader \
  --teleop.port=/dev/ttyACM0 \
  --teleop.id=leader_arm_v1 \
  --display_data=false \
  --dataset.repo_id=${USER}/eval_so101_stack_blue_on_second_layer_v4_act \
  --dataset.single_task="stack_green_on_bottom" \
  --dataset.num_episodes=1 \
  --dataset.episode_time_s=30 \
  --dataset.fps=30 \
  --dataset.push_to_hub=false \
  --dataset.video=true \
  --play_sounds=false \
  --policy.path=outputs/act/so101_stack_blue_on_second_layer_v4_act/checkpoints/last/pretrained_model
  
  
  
 rm -rf ~/.cache/huggingface/lerobot/cao/eval_so101_stack_blue_on_second_layer_v4_act
```

**评估 "so101\_blue\_mix\_v456"**

```bash
  lerobot-record \
  --robot.type=so101_follower \
  --robot.port=/dev/ttyACM1 \
  --robot.id=follower_arm_v1 \
  --robot.cameras="{ top: {type: opencv, index_or_path: /dev/video0, width: 320, height: 240, fps: 30}, hand: {type: opencv, index_or_path: /dev/video2, width: 640, height: 480, fps: 30} }" \
  --teleop.type=so101_leader \
  --teleop.port=/dev/ttyACM0 \
  --teleop.id=leader_arm_v1 \
  --display_data=false \
  --dataset.repo_id=${USER}/eval_so101_blue_mix_v456 \
  --dataset.single_task="stack_blue_on_second_layer" \
  --dataset.num_episodes=1 \
  --dataset.episode_time_s=30 \
  --dataset.fps=30 \
  --dataset.push_to_hub=false \
  --dataset.video=true \
  --play_sounds=false \
  --policy.path=outputs/act/so101_blue_mix_v456/checkpoints/last/pretrained_model

  

 rm -rf ~/.cache/huggingface/lerobot/cao/eval_so101_blue_mix_v456
```
